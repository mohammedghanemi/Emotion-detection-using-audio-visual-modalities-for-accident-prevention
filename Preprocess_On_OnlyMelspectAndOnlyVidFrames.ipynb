{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from decord import VideoReader\n",
    "from moviepy.editor import AudioFileClip\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "import shutil\n",
    "\n",
    "input_size = 224\n",
    "num_frame = 8\n",
    "sampling_rate = 6\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    return audio / np.max(np.abs(audio))\n",
    "\n",
    "def mel_spectrogram(signal, sample_rate, n_mels=128, fmax=8000):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_mels=n_mels, fmax=fmax)\n",
    "    return librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "def read_video(file_path):\n",
    "    vr = VideoReader(file_path)\n",
    "    frames = vr.get_batch(range(len(vr))).asnumpy()\n",
    "    return format_frames(frames, output_size=(input_size, input_size))\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.uint8)\n",
    "    frame = tf.image.resize(frame, size=list(output_size))\n",
    "    return frame\n",
    "\n",
    "def uniform_temporal_subsample(x, num_samples, clip_idx, total_clips, frame_rate=1, temporal_dim=-4):\n",
    "    t = tf.cast(tf.shape(x)[temporal_dim], tf.float32)\n",
    "    max_offset = t - num_samples * frame_rate\n",
    "    step = max_offset // total_clips\n",
    "    offset = clip_idx * step\n",
    "    indices = tf.linspace(offset, offset + (num_samples - 1) * frame_rate, num_samples)\n",
    "    indices = tf.clip_by_value(indices, 0, t - 1)\n",
    "    indices = tf.cast(tf.round(indices), tf.int32)\n",
    "    return tf.gather(x, indices, axis=temporal_dim)\n",
    "\n",
    "def clip_generator(image, num_frames=32, frame_rate=1, num_clips=1, crop_size=224):\n",
    "    clips_list = []\n",
    "    for i in range(num_clips):\n",
    "        frame = uniform_temporal_subsample(image, num_frames, i, num_clips, frame_rate=frame_rate, temporal_dim=0)\n",
    "        clips_list.append(frame)\n",
    "    return tf.reshape(tf.stack(clips_list), [num_clips*num_frames, crop_size, crop_size, 3])\n",
    "\n",
    "def video_audio(path, melspect_path, videoframes_path):\n",
    "    os.makedirs(melspect_path, exist_ok=True)\n",
    "    os.makedirs(videoframes_path, exist_ok=True)\n",
    "\n",
    "    for video_file in os.listdir(path):\n",
    "        video_path = os.path.join(path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "        \n",
    "        melspect_video_path = os.path.join(melspect_path, f\"{video_name}_melspect_only.mp4\")\n",
    "        videoframes_video_path = os.path.join(videoframes_path, f\"{video_name}_videoframes_only.mp4\")\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        melspect_video = cv2.VideoWriter(melspect_video_path, fourcc, 16.0, (224, 224))\n",
    "        videoframes_video = cv2.VideoWriter(videoframes_video_path, fourcc, 16.0, (224, 224))\n",
    "\n",
    "        \n",
    "        video_ds = read_video(video_path)\n",
    "        video_ds = clip_generator(video_ds, num_frame, sampling_rate, num_clips=1)\n",
    "\n",
    "        \n",
    "        audio_clip = AudioFileClip(video_path)\n",
    "        wave_name = os.path.join(path, f\"{video_name}.wav\")\n",
    "        audio_clip.write_audiofile(wave_name)\n",
    "        fs, audio_data = wavfile.read(wave_name)\n",
    "        audio_data = normalize_audio(audio_data)\n",
    "        step = fs // 16\n",
    "\n",
    "        \n",
    "        for i in range(8):\n",
    "            signal = audio_data[i * step:(i + 1) * step]\n",
    "            mel_spec = mel_spectrogram(signal, fs)\n",
    "\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(4, 4))\n",
    "            ax.imshow(mel_spec, aspect='auto', origin='lower', cmap='magma')\n",
    "            plt.axis('off')\n",
    "            fig.canvas.draw()\n",
    "            \n",
    "            audio_img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            audio_img = audio_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "            audio_img = cv2.resize(audio_img, (224, 224))\n",
    "            plt.close(fig)\n",
    "            \n",
    "            \n",
    "            melspect_video.write(audio_img)\n",
    "\n",
    "        \n",
    "        for i in range(8):\n",
    "            video_img = video_ds[i].numpy().astype('uint8')\n",
    "            videoframes_video.write(video_img)\n",
    "\n",
    "        \n",
    "        melspect_video.release()\n",
    "        videoframes_video.release()\n",
    "        #os.remove(wave_name)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #input_path = r\"D:\\eNTERFACE\\all_avi_files\"  # Path containing the original .avi files\n",
    "    #melspect_output_path = r\"D:\\eNTERFACE\\melspect_only\"  # Output path for mel spectrogram videos\n",
    "    #videoframes_output_path = r\"D:\\eNTERFACE\\videoframes_only\"  # Output path for video frames videos\n",
    "\n",
    "    #video_audio(input_path, melspect_output_path, videoframes_output_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from decord import VideoReader\n",
    "from moviepy.editor import AudioFileClip\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from PIL import Image\n",
    "\n",
    "input_size = 224\n",
    "num_frame = 8\n",
    "sampling_rate = 6\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    return audio / np.max(np.abs(audio))\n",
    "\n",
    "def mel_spectrogram(signal, sample_rate, n_mels=128, fmax=8000):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_mels=n_mels, fmax=fmax)\n",
    "    return librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "def read_video(file_path):\n",
    "    vr = VideoReader(file_path)\n",
    "    frames = vr.get_batch(range(len(vr))).asnumpy()\n",
    "    return format_frames(frames, output_size=(input_size, input_size))\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.uint8)\n",
    "    frame = tf.image.resize(frame, size=list(output_size))\n",
    "    return frame\n",
    "\n",
    "def uniform_temporal_subsample(x, num_samples, clip_idx, total_clips, frame_rate=1, temporal_dim=-4):\n",
    "    t = tf.cast(tf.shape(x)[temporal_dim], tf.float32)  # Ensure t is float32\n",
    "    max_offset = t - num_samples * frame_rate\n",
    "    step = max_offset // total_clips\n",
    "    offset = clip_idx * step\n",
    "    indices = tf.linspace(offset, offset + (num_samples - 1) * frame_rate, num_samples)\n",
    "    indices = tf.clip_by_value(indices, 0, t - 1)  # Use t as float32\n",
    "    indices = tf.cast(tf.round(indices), tf.int32)\n",
    "    return tf.gather(x, indices, axis=temporal_dim)\n",
    "\n",
    "def clip_generator(image, num_frames=32, frame_rate=1, num_clips=1, crop_size=224):\n",
    "    clips_list = []\n",
    "    for i in range(num_clips):\n",
    "        frame = uniform_temporal_subsample(image, num_frames, i, num_clips, frame_rate=frame_rate, temporal_dim=0)\n",
    "        clips_list.append(frame)\n",
    "    return tf.reshape(tf.stack(clips_list), [num_clips*num_frames, crop_size, crop_size, 3])\n",
    "\n",
    "def video_audio(path, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    for video_file in os.listdir(path):\n",
    "        video_path = os.path.join(path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        path_video_save = os.path.join(save_path, f\"{video_name}.mp4\")\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        output_video = cv2.VideoWriter(path_video_save, fourcc, 16.0, (224, 224))\n",
    "\n",
    "        video_ds = read_video(video_path)\n",
    "        video_ds = clip_generator(video_ds, num_frame, sampling_rate, num_clips=1)\n",
    "\n",
    "        audio_clip = AudioFileClip(video_path)\n",
    "        wave_name = os.path.join(save_path, f\"{video_name}.wav\")\n",
    "        audio_clip.write_audiofile(wave_name)\n",
    "        fs, audio_data = wavfile.read(wave_name)\n",
    "        audio_data = normalize_audio(audio_data)\n",
    "        step = fs // 16\n",
    "\n",
    "        for i in range(8):\n",
    "            signal = audio_data[i * step:(i + 1) * step]\n",
    "            mel_spec = mel_spectrogram(signal, fs)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(4, 4))\n",
    "            ax.imshow(mel_spec, aspect='auto', origin='lower', cmap='magma')\n",
    "            plt.axis('off')\n",
    "            fig.canvas.draw()\n",
    "            \n",
    "            audio_img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            audio_img = audio_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "            audio_img = cv2.resize(audio_img, (224, 224))\n",
    "            plt.close(fig)\n",
    "            \n",
    "            output_video.write(audio_img)\n",
    "\n",
    "        for i in range(8):\n",
    "            video_img = video_ds[i].numpy().astype('uint8')\n",
    "            output_video.write(video_img)\n",
    "\n",
    "        output_video.release()\n",
    "        #os.remove(wave_name)  # Remove the temporary WAV file after processing\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #input_path = r\"D:\\eNTERFACE\\all_avi_files\"  # Path containing the 1263 .avi files\n",
    "    #output_path = r\"D:\\eNTERFACE\\melspect_videoframes\"       # Output path to save only .mp4 files\n",
    "\n",
    "    #video_audio(input_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
